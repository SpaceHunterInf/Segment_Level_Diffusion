{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xz479/miniconda3/envs/latent-diff/lib/python3.8/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing.spawn import prepare\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Value\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def read_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSONL (JSON Lines) file and returns a list of dictionaries.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the JSONL file.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries where each dictionary represents a JSON object from the file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line.strip()))\n",
    "    return data\n",
    "\n",
    "class utt_dataset(Dataset):\n",
    "    def __init__(self, data, encoder_tokenizer, decoder_tokenizer, max_length=64, noiser=None, cse=False):\n",
    "        self.data = data\n",
    "        self.encoder_tokenizer = encoder_tokenizer\n",
    "        self.decoder_tokenizer = decoder_tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.noiser = noiser\n",
    "        self.cse = cse\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Get the text data at the specified index\n",
    "        if 'src' in self.data[index].keys():\n",
    "            text = self.data[index]['src']\n",
    "        elif 'text' in self.data[index].keys():\n",
    "            text = self.data[index]['text']\n",
    "        \n",
    "        # Tokenize the input text using the encoder tokenizer\n",
    "        encoder_input = self.encoder_tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize the input text using the decoder tokenizer\n",
    "        decoder_input = self.decoder_tokenizer.encode_plus(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Apply noise to the encoder input IDs if a noiser is provided\n",
    "        if self.noiser:\n",
    "            noisy_encoder_input_ids = self.noiser(encoder_input['input_ids'].squeeze())\n",
    "        else:\n",
    "            noisy_encoder_input_ids = encoder_input['input_ids'].squeeze()\n",
    "        \n",
    "        # Prepare the dictionary for returning the data\n",
    "        x = {\n",
    "            'text':text,\n",
    "            'encoder_input_ids': noisy_encoder_input_ids,\n",
    "            'decoder_input_ids': decoder_input['input_ids'].squeeze(),\n",
    "            'attention_mask': encoder_input['attention_mask'].squeeze(),\n",
    "            'decoder_attention_mask': decoder_input['attention_mask'].squeeze()\n",
    "        }\n",
    "        \n",
    "        if self.cse: #more stuff for contrastive learning\n",
    "            x['has_similar'] = 'similar' in self.data[index].keys()\n",
    "            x['has_contrastive'] = 'contrastive' in self.data[index].keys()\n",
    "            \n",
    "            item = self.data[index]\n",
    "            # Add similar sentences if they exist\n",
    "            if 'similar' in item.keys():\n",
    "                similar_input = self.encoder_tokenizer.encode_plus(\n",
    "                    item['similar'],\n",
    "                    padding='max_length',\n",
    "                    max_length=self.max_length,\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                x['similar_ids'] = similar_input['input_ids']\n",
    "                x['similar_attention_mask'] = similar_input['attention_mask']\n",
    "\n",
    "            # Add contrastive sentences if they exist\n",
    "            if 'contrastive' in item.keys():\n",
    "                contrastive_input = self.encoder_tokenizer.encode_plus(\n",
    "                    item['contrastive'],\n",
    "                    padding='max_length',\n",
    "                    max_length=self.max_length,\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                x['contrastive_ids'] = contrastive_input['input_ids']\n",
    "                x['contrastive_attention_mask'] = contrastive_input['attention_mask']\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "def collate_fn(batch, encoder_tokenizer=None, decoder_tokenizer=None, cse=False):\n",
    "    # Extract sequences from the batch\n",
    "    encoder_input_ids = [item['encoder_input_ids'] for item in batch]\n",
    "    decoder_input_ids = [item['decoder_input_ids'] for item in batch]\n",
    "    attention_masks = [item['attention_mask'] for item in batch]\n",
    "    decoder_attention_masks = [item['decoder_attention_mask'] for item in batch]\n",
    "    \n",
    "    # Pad sequences to the maximum length within the batch\n",
    "    encoder_input_ids = torch.nn.utils.rnn.pad_sequence(encoder_input_ids, batch_first=True, padding_value=0)\n",
    "    decoder_input_ids = torch.nn.utils.rnn.pad_sequence(decoder_input_ids, batch_first=True, padding_value=0)\n",
    "    attention_masks = torch.nn.utils.rnn.pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "    decoder_attention_masks = torch.nn.utils.rnn.pad_sequence(decoder_attention_masks, batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Decode to text (ignoring the pad tokens)\n",
    "    decoded_encoder_texts = [\n",
    "        encoder_tokenizer.decode(ids, skip_special_tokens=True) \n",
    "        for ids in encoder_input_ids\n",
    "    ]\n",
    "    \n",
    "    decoded_decoder_texts = [\n",
    "        decoder_tokenizer.decode(ids, skip_special_tokens=True)\n",
    "        for ids in decoder_input_ids\n",
    "    ]\n",
    "    \n",
    "    labels = decoder_input_ids.clone()\n",
    "    \n",
    "    # Set padding tokens in labels to -100 to ignore them in the loss computation\n",
    "    labels[labels == 0] = -100\n",
    "    \n",
    "    batch_dict = {\n",
    "        'encoder_input_ids': encoder_input_ids,\n",
    "        'decoder_input_ids': decoder_input_ids,\n",
    "        'attention_mask': attention_masks,\n",
    "        'decoder_attention_mask': decoder_attention_masks,\n",
    "        'decoded_encoder_texts': decoded_encoder_texts,\n",
    "        'decoded_decoder_texts': decoded_decoder_texts,\n",
    "        'label_ids': labels\n",
    "    }\n",
    "    \n",
    "    if cse:\n",
    "        has_similar = torch.tensor([item['has_similar'] for item in batch])\n",
    "        has_contrastive = torch.tensor([item['has_contrastive'] for item in batch])\n",
    "                # Handle similar sentences if they exist\n",
    "        if any(has_similar):\n",
    "            similar_ids = [item['similar_ids'] for item in batch if 'similar_ids' in item]\n",
    "            similar_attention_mask = [item['similar_attention_mask'] for item in batch if 'similar_attention_mask' in item]\n",
    "            if similar_ids:\n",
    "                batch_dict['similar_ids'] = torch.nn.utils.rnn.pad_sequence(similar_ids, batch_first=True, padding_value=0).squeeze(1)\n",
    "                batch_dict['similar_attention_mask'] = torch.nn.utils.rnn.pad_sequence(similar_attention_mask, batch_first=True, padding_value=0).squeeze(1)\n",
    "\n",
    "        # Handle contrastive sentences if they exist\n",
    "        if any(has_contrastive):\n",
    "            contrastive_ids = [item['contrastive_ids'] for item in batch if 'contrastive_ids' in item]\n",
    "            contrastive_attention_mask = [item['contrastive_attention_mask'] for item in batch if 'contrastive_attention_mask' in item]\n",
    "            if contrastive_ids:\n",
    "                batch_dict['contrastive_ids'] = torch.nn.utils.rnn.pad_sequence(contrastive_ids, batch_first=True, padding_value=0).squeeze(1)\n",
    "                batch_dict['contrastive_attention_mask'] = torch.nn.utils.rnn.pad_sequence(contrastive_attention_mask, batch_first=True, padding_value=0).squeeze(1)\n",
    "\n",
    "    return batch_dict\n",
    "\n",
    "def get_dataloader(data, encoder_tokenizer, decoder_tokenizer, batch_size=32, max_length=64, noiser=None, shuffle=True, cse=False):\n",
    "    \"\"\"\n",
    "    Creates a DataLoader for the given dataset.\n",
    "\n",
    "    Args:\n",
    "    - data (list): List of datapoints, each being a dictionary with a 'text' field.\n",
    "    - encoder_tokenizer (transformers.PreTrainedTokenizer): Tokenizer for the encoder.\n",
    "    - decoder_tokenizer (transformers.PreTrainedTokenizer): Tokenizer for the decoder.\n",
    "    - batch_size (int): Number of samples per batch to load.\n",
    "    - max_length (int): Maximum sequence length for the tokenized inputs.\n",
    "    - noiser (callable, optional): Function to add noise to the encoder input IDs.\n",
    "    - shuffle (bool): Whether to shuffle the data at every epoch.\n",
    "\n",
    "    Returns:\n",
    "    - DataLoader: DataLoader for the dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = utt_dataset(\n",
    "        data=data,\n",
    "        encoder_tokenizer=encoder_tokenizer,\n",
    "        decoder_tokenizer=decoder_tokenizer,\n",
    "        max_length=max_length,\n",
    "        noiser=noiser,\n",
    "        cse=cse\n",
    "    )\n",
    "\n",
    "    # Create the DataLoader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=partial(collate_fn, encoder_tokenizer=encoder_tokenizer, decoder_tokenizer=decoder_tokenizer, cse=cse)\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "def get_utt_dataloader(file_path, encoder_tokenizer, decoder_tokenizer, max_length=64, noiser=None, batch_size=32, dev_mode=False, cse=False):\n",
    "    \n",
    "    if '.jsonl' in file_path:\n",
    "        data = read_jsonl(file_path)\n",
    "    else:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "    \n",
    "    if dev_mode:\n",
    "        data=data[:100]\n",
    "    \n",
    "    dataloader = get_dataloader(data, encoder_tokenizer, decoder_tokenizer, \n",
    "                                max_length=max_length, noiser=noiser, batch_size=batch_size, cse=cse)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xz479/miniconda3/envs/latent-diff/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/xz479/miniconda3/envs/latent-diff/lib/python3.8/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xz479/miniconda3/envs/latent-diff/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {\n",
    "        'input': 'How are you?',\n",
    "        'output': 'I am fine.',\n",
    "        'similar': 'How do you do?'\n",
    "    },\n",
    "    {\n",
    "        'input': 'What is the weather?',\n",
    "        'output': 'It is sunny.',\n",
    "        'contrastive': 'I like pizza.'\n",
    "    },\n",
    "    {\n",
    "        'input': 'Tell me a joke',\n",
    "        'output': 'Why did the chicken cross the road?'\n",
    "    }\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader\n",
    "dataloader = get_utt_dataloader('../datasets/nli_for_simcse_utt/dev.jsonl', tokenizer, tokenizer, dev_mode=True, cse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoder_input_ids': tensor([[   37,   388,    19,  ...,     0,     0,     0],\n",
      "        [ 8548,  7494, 17926,  ...,     0,     0,     0],\n",
      "        [   71,  1021,  4940,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  438,  2937, 15618,  ...,     0,     0,     0],\n",
      "        [   71,  1021,  3202,  ...,     0,     0,     0],\n",
      "        [ 5245, 27424,     7,  ...,     0,     0,     0]]), 'decoder_input_ids': tensor([[   37,   388,    19,  ...,     0,     0,     0],\n",
      "        [ 8548,  7494, 17926,  ...,     0,     0,     0],\n",
      "        [   71,  1021,  4940,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  438,  2937, 15618,  ...,     0,     0,     0],\n",
      "        [   71,  1021,  3202,  ...,     0,     0,     0],\n",
      "        [ 5245, 27424,     7,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoded_encoder_texts': ['The man is dancing with a doll wearing a red dress and heels.', 'tourist riding elephants in the water with a field in the background.', 'A young boy sliding down a water slide toy.', 'A child dressed in a white coat paints an image on the paper laying on the table.', 'Children in uniforms, pads and halmets play football', 'A young man is selling ice pops and sodas wearing a sweater on his hips.', 'Three people are standing in front of an arcade.', 'A father and son enjoying lunch after a morning of shopping.', 'The fast pitch is destined to become a home run for the team.', 'A parachuting man gets ready to land.', 'A woman is in a red sweater spinning a hula-hoop around her waist.', 'A football team is running as the kicker touches the football with his foot.', 'Two dogs, that are tied to the building, patiently wait for their master to return.', 'There are a crowd of people sitting underneath shady trees.', 'Four children, in uniforms of two different teams, are playing football.', 'A man in a white shirt reads the paper by a tree.', 'A competition is occurring between three people in a swimming pool.', 'A baseball player takes a swing at a pitch while the crowd watches.', 'Two soccer players walk on the soccer field.', 'A baseball player prepares to swing the bat at a pitched ball.', 'Woman and older man are walking side-by-side on treadmills in a fitness room.', 'Soccer goalie talks things over with the opposing team.', 'A trio of elephants are carrying riders across shallow running water.', 'The young girl is running on a sandy beach.', 'Girl on a street using a hula hoop, with three people in the background.', 'An older man and woman exercise on treadmills.', 'two opposing soccer team players communicating', 'Four young boys dressed in uniform play football.', 'An older man in a gray sweater and blue pants is shaping something in a forge on an anvil.', 'With focused gazes, three uniquely dressed actors stare off-stage.', 'A young girl plays with a \"Thomas the Tank Engine\" train set at a store.', 'Three swimmers swim in their respective lanes.'], 'decoded_decoder_texts': ['The man is dancing with a doll wearing a red dress and heels.', 'tourist riding elephants in the water with a field in the background.', 'A young boy sliding down a water slide toy.', 'A child dressed in a white coat paints an image on the paper laying on the table.', 'Children in uniforms, pads and halmets play football', 'A young man is selling ice pops and sodas wearing a sweater on his hips.', 'Three people are standing in front of an arcade.', 'A father and son enjoying lunch after a morning of shopping.', 'The fast pitch is destined to become a home run for the team.', 'A parachuting man gets ready to land.', 'A woman is in a red sweater spinning a hula-hoop around her waist.', 'A football team is running as the kicker touches the football with his foot.', 'Two dogs, that are tied to the building, patiently wait for their master to return.', 'There are a crowd of people sitting underneath shady trees.', 'Four children, in uniforms of two different teams, are playing football.', 'A man in a white shirt reads the paper by a tree.', 'A competition is occurring between three people in a swimming pool.', 'A baseball player takes a swing at a pitch while the crowd watches.', 'Two soccer players walk on the soccer field.', 'A baseball player prepares to swing the bat at a pitched ball.', 'Woman and older man are walking side-by-side on treadmills in a fitness room.', 'Soccer goalie talks things over with the opposing team.', 'A trio of elephants are carrying riders across shallow running water.', 'The young girl is running on a sandy beach.', 'Girl on a street using a hula hoop, with three people in the background.', 'An older man and woman exercise on treadmills.', 'two opposing soccer team players communicating', 'Four young boys dressed in uniform play football.', 'An older man in a gray sweater and blue pants is shaping something in a forge on an anvil.', 'With focused gazes, three uniquely dressed actors stare off-stage.', 'A young girl plays with a \"Thomas the Tank Engine\" train set at a store.', 'Three swimmers swim in their respective lanes.'], 'label_ids': tensor([[   37,   388,    19,  ...,  -100,  -100,  -100],\n",
      "        [ 8548,  7494, 17926,  ...,  -100,  -100,  -100],\n",
      "        [   71,  1021,  4940,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [  438,  2937, 15618,  ...,  -100,  -100,  -100],\n",
      "        [   71,  1021,  3202,  ...,  -100,  -100,  -100],\n",
      "        [ 5245, 27424,     7,  ...,  -100,  -100,  -100]]), 'similar_ids': tensor([[  290,    19,     3,  ...,     0,     0,     0],\n",
      "        [16471,    19,  7494,  ...,     0,     0,     0],\n",
      "        [   71,  1021,  4940,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   37,   386, 10485,  ...,     0,     0,     0],\n",
      "        [   37,  3202,    19,  ...,     0,     0,     0],\n",
      "        [27813,  5567,    33,  ...,     0,     0,     0]]), 'similar_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'contrastive_ids': tensor([[   37,   388,    11,  ...,     0,     0,     0],\n",
      "        [   37, 17926,    19,  ...,     0,     0,     0],\n",
      "        [   71,  3202,    19,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   37,   386, 10485,  ...,     0,     0,     0],\n",
      "        [   37,  3202,    19,  ...,     0,     0,     0],\n",
      "        [ 5245,   151,    33,  ...,     0,     0,     0]]), 'contrastive_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'encoder_input_ids': tensor([[ 2759,   872,  3887,  ...,     0,     0,     0],\n",
      "        [ 6578,  2765,    33,  ...,     0,     0,     0],\n",
      "        [  555,  3202,  3793,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   71,   568,  5119,  ...,     0,     0,     0],\n",
      "        [   71,  5868,  2335,  ...,     0,     0,     0],\n",
      "        [   71,  3202, 11986,  ...,     0,     0,     0]]), 'decoder_input_ids': tensor([[ 2759,   872,  3887,  ...,     0,     0,     0],\n",
      "        [ 6578,  2765,    33,  ...,     0,     0,     0],\n",
      "        [  555,  3202,  3793,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [   71,   568,  5119,  ...,     0,     0,     0],\n",
      "        [   71,  5868,  2335,  ...,     0,     0,     0],\n",
      "        [   71,  3202, 11986,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoded_encoder_texts': ['Two white dogs are looking out into the street and are sitting next to a white bicycle.', 'Asian workers are working hard.', 'One girl throws water on another in a pool.', 'A large crowd of people jumps with their hands in the air on a green lawn.', 'A man in a polo shirt sits in a chair looking at a computer screen.', 'A girl is throwing a bucket of water at another girl in a pool.', 'In pool surrounded by plants, one smiling girl with a bucket splashes another girl.', 'Three people in various stages of swimming strokes race along colorful lane markers.', 'A person on an ATV in dunes with a purple sky.', 'Two people running on a treadmill inside.', 'Two men in hiking boots strike martial arts poses.', 'A man eyes the ground as he comes in for a landing from parasailing.', 'A dog walking on a beach', 'The dog on the beach has gotten a hold of something.', 'A baseball player is about to hit a ball while a female behind a protective screen is watching him.', 'Two Santa dancing on concrete.', 'A very adventurous snowboarder rips through powder snow with speed, agility, and concentration.', 'A tan dog dragging a deflated innertube down the beach.', 'A woman in a blue shirt playing a wind instrument.', 'Three vikings walking on the boardwalk.', 'A young girl playing clarinet in a musical group.', 'Two people in dirty clothes are walking in a parking lot with large backpacks.', 'Firefighters converse with a man at the scene of an emergency.', 'A dog has a wetsuit in his mouth on the beach.', 'A brunette woman holds a child in a busy daycare.', 'A man surfs by the Golden Gate bridge on a foggy day.', 'A man is wearing a hat regarding beer.', 'Two dogs on leashes get close together.', 'Person snowboarding downwards in the snow, wearing snow gear.', 'A person wearing a blue and yellow snowsuit, a blue helmet and snow goggles is moving down a snow covered incline.', 'A younger woman and older man run on treadmills.', 'A girl dumps a bucket of water on another girl.'], 'decoded_decoder_texts': ['Two white dogs are looking out into the street and are sitting next to a white bicycle.', 'Asian workers are working hard.', 'One girl throws water on another in a pool.', 'A large crowd of people jumps with their hands in the air on a green lawn.', 'A man in a polo shirt sits in a chair looking at a computer screen.', 'A girl is throwing a bucket of water at another girl in a pool.', 'In pool surrounded by plants, one smiling girl with a bucket splashes another girl.', 'Three people in various stages of swimming strokes race along colorful lane markers.', 'A person on an ATV in dunes with a purple sky.', 'Two people running on a treadmill inside.', 'Two men in hiking boots strike martial arts poses.', 'A man eyes the ground as he comes in for a landing from parasailing.', 'A dog walking on a beach', 'The dog on the beach has gotten a hold of something.', 'A baseball player is about to hit a ball while a female behind a protective screen is watching him.', 'Two Santa dancing on concrete.', 'A very adventurous snowboarder rips through powder snow with speed, agility, and concentration.', 'A tan dog dragging a deflated innertube down the beach.', 'A woman in a blue shirt playing a wind instrument.', 'Three vikings walking on the boardwalk.', 'A young girl playing clarinet in a musical group.', 'Two people in dirty clothes are walking in a parking lot with large backpacks.', 'Firefighters converse with a man at the scene of an emergency.', 'A dog has a wetsuit in his mouth on the beach.', 'A brunette woman holds a child in a busy daycare.', 'A man surfs by the Golden Gate bridge on a foggy day.', 'A man is wearing a hat regarding beer.', 'Two dogs on leashes get close together.', 'Person snowboarding downwards in the snow, wearing snow gear.', 'A person wearing a blue and yellow snowsuit, a blue helmet and snow goggles is moving down a snow covered incline.', 'A younger woman and older man run on treadmills.', 'A girl dumps a bucket of water on another girl.'], 'label_ids': tensor([[ 2759,   872,  3887,  ...,  -100,  -100,  -100],\n",
      "        [ 6578,  2765,    33,  ...,  -100,  -100,  -100],\n",
      "        [  555,  3202,  3793,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [   71,   568,  5119,  ...,  -100,  -100,  -100],\n",
      "        [   71,  5868,  2335,  ...,  -100,  -100,  -100],\n",
      "        [   71,  3202, 11986,  ...,  -100,  -100,  -100]]), 'similar_ids': tensor([[ 506, 8636,   33,  ...,    0,    0,    0],\n",
      "        [  37, 2765,   13,  ...,    0,    0,    0],\n",
      "        [ 555,  568, 3793,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  37,  568,   19,  ...,    0,    0,    0],\n",
      "        [2759,  151,   33,  ...,    0,    0,    0],\n",
      "        [  71, 3202,  171,  ...,    0,    0,    0]]), 'similar_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'contrastive_ids': tensor([[2759,  150,   18,  ...,    0,    0,    0],\n",
      "        [  37, 3746,    7,  ...,    0,    0,    0],\n",
      "        [ 555, 4940, 3793,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [  37,  568, 5119,  ...,    0,    0,    0],\n",
      "        [2759,  151,   33,  ...,    0,    0,    0],\n",
      "        [2759, 5234,   33,  ...,    0,    0,    0]]), 'contrastive_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'encoder_input_ids': tensor([[   71,   563,    13,  ...,     0,     0,     0],\n",
      "        [   71,   388,    16,  ...,     0,     0,     0],\n",
      "        [   71,  9360,  4125,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 5412,    18, 24790,  ...,     0,     0,     0],\n",
      "        [  389,   797,  3370,  ...,     0,     0,     0],\n",
      "        [   37,   388,    30,  ...,     0,     0,     0]]), 'decoder_input_ids': tensor([[   71,   563,    13,  ...,     0,     0,     0],\n",
      "        [   71,   388,    16,  ...,     0,     0,     0],\n",
      "        [   71,  9360,  4125,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [ 5412,    18, 24790,  ...,     0,     0,     0],\n",
      "        [  389,   797,  3370,  ...,     0,     0,     0],\n",
      "        [   37,   388,    30,  ...,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'decoded_encoder_texts': ['A group of little boys play football in uniforms.', 'A man in sandals sits down while reading the newspaper outside.', 'A lady standing near the counter of a bakery smiling at the camera.', 'A football team running down the field with the quarterback making the kickoff.', 'A big mascot is dancing on a field while two people are talking.', 'A dog on a beach dragging an item', 'Three Asian women having a conversation.', 'The mascot is dancing in the background while a couple has a conversation.', 'A woman in a blue shirt is playing an instrument.', 'Three costumed stage performers act out a scene.', 'Firefighters wear reflective uniforms and stare upwards.', 'A younger woman and older man are running on treadmills next to each other.', 'The girls are playing soccer.', 'A girl in a blue shirt and glasses plays the clarinet in front of a microphone.', 'A man in a white shirt is sitting on a curb and reading a newspaper.', 'There is a large group of people standing in grass with most of them holding their hands in the air.', 'A bunch of tourists out taking photos or a family reunion photograph with a whole bunch of people by some cut out people and trees with their hands up in the air like they are jumping.', 'A small child wearing a white hat reaches for a paintbrush.', 'A white dog is leaning against a golden colored dog.', 'A man hanging just above the ground.', 'A little girl in a flower swimsuit running across the beach with waves in the background.', 'The girls are playing in the pool and splashing each other with water.', 'Football players in white, red, and black uniforms run down the field by the 30 yard line.', 'Two soccer players walk off the field as the crowd is standing in their seats.', 'A man is in the desert a few feet off the ground holding onto strings of a parachute.', 'Two men dressed as Santa Clause dancing on a wall in front of two spectators.', 'A bunch of birds flying towards a building with an antenna in the background amid a beautiful sunset.', 'A woman wearing a red jacket hula-hoops in the street.', 'The little girl with the white hat and white shirt is painting.', 'Arm-strokes from swimmers who are racing in the pool.', 'An American football punter is just about to kick the ball to the receiving team with the rest of his team running behind him.', 'The man on the left is looking at the woman and the man.'], 'decoded_decoder_texts': ['A group of little boys play football in uniforms.', 'A man in sandals sits down while reading the newspaper outside.', 'A lady standing near the counter of a bakery smiling at the camera.', 'A football team running down the field with the quarterback making the kickoff.', 'A big mascot is dancing on a field while two people are talking.', 'A dog on a beach dragging an item', 'Three Asian women having a conversation.', 'The mascot is dancing in the background while a couple has a conversation.', 'A woman in a blue shirt is playing an instrument.', 'Three costumed stage performers act out a scene.', 'Firefighters wear reflective uniforms and stare upwards.', 'A younger woman and older man are running on treadmills next to each other.', 'The girls are playing soccer.', 'A girl in a blue shirt and glasses plays the clarinet in front of a microphone.', 'A man in a white shirt is sitting on a curb and reading a newspaper.', 'There is a large group of people standing in grass with most of them holding their hands in the air.', 'A bunch of tourists out taking photos or a family reunion photograph with a whole bunch of people by some cut out people and trees with their hands up in the air like they are jumping.', 'A small child wearing a white hat reaches for a paintbrush.', 'A white dog is leaning against a golden colored dog.', 'A man hanging just above the ground.', 'A little girl in a flower swimsuit running across the beach with waves in the background.', 'The girls are playing in the pool and splashing each other with water.', 'Football players in white, red, and black uniforms run down the field by the 30 yard line.', 'Two soccer players walk off the field as the crowd is standing in their seats.', 'A man is in the desert a few feet off the ground holding onto strings of a parachute.', 'Two men dressed as Santa Clause dancing on a wall in front of two spectators.', 'A bunch of birds flying towards a building with an antenna in the background amid a beautiful sunset.', 'A woman wearing a red jacket hula-hoops in the street.', 'The little girl with the white hat and white shirt is painting.', 'Arm-strokes from swimmers who are racing in the pool.', 'An American football punter is just about to kick the ball to the receiving team with the rest of his team running behind him.', 'The man on the left is looking at the woman and the man.'], 'label_ids': tensor([[   71,   563,    13,  ...,  -100,  -100,  -100],\n",
      "        [   71,   388,    16,  ...,  -100,  -100,  -100],\n",
      "        [   71,  9360,  4125,  ...,  -100,  -100,  -100],\n",
      "        ...,\n",
      "        [ 5412,    18, 24790,  ...,  -100,  -100,  -100],\n",
      "        [  389,   797,  3370,  ...,  -100,  -100,  -100],\n",
      "        [   37,   388,    30,  ...,  -100,  -100,  -100]]), 'similar_ids': tensor([[   71,   563,    13,  ...,     0,     0,     0],\n",
      "        [   71,   388,    19,  ...,     0,     0,     0],\n",
      "        [   37,  9360,    19,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [27813,  5567,    33,  ...,     0,     0,     0],\n",
      "        [    3,     9,  1959,  ...,     0,     0,     0],\n",
      "        [    8,   388,    19,  ...,     0,     0,     0]]), 'similar_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'contrastive_ids': tensor([[  71,  563,   13,  ...,    0,    0,    0],\n",
      "        [  37,  388,   19,  ...,    0,    0,    0],\n",
      "        [  37, 9360,   19,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 465,   80,   19,  ...,    0,    0,    0],\n",
      "        [   8, 1959,   19,  ...,    0,    0,    0],\n",
      "        [   3,    9, 2335,  ...,    0,    0,    0]]), 'contrastive_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "{'encoder_input_ids': tensor([[  290,    19,     3,     9,   385,  3202,  1180,    30,     8,  2608,\n",
      "             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2759, 26675,    33,  3823,   544,   416,    12,     3,     9,  3724,\n",
      "            30,  1001,  6428,    26,  7091,     5,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 5245, 27424,     7,    33,  5989,    42,  8191,    16,  2450,    50,\n",
      "          1496,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2759,  3887, 13060,   284,   119,     5,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'decoder_input_ids': tensor([[  290,    19,     3,     9,   385,  3202,  1180,    30,     8,  2608,\n",
      "             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2759, 26675,    33,  3823,   544,   416,    12,     3,     9,  3724,\n",
      "            30,  1001,  6428,    26,  7091,     5,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 5245, 27424,     7,    33,  5989,    42,  8191,    16,  2450,    50,\n",
      "          1496,     5,     1,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2759,  3887, 13060,   284,   119,     5,     1,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'decoder_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'decoded_encoder_texts': ['There is a little girl running on the beach.', 'Two puppies are sitting together next to a bike on black tiled flooring.', 'Three swimmers are swimming or racing in separate lanes.', 'Two dogs groom each other.'], 'decoded_decoder_texts': ['There is a little girl running on the beach.', 'Two puppies are sitting together next to a bike on black tiled flooring.', 'Three swimmers are swimming or racing in separate lanes.', 'Two dogs groom each other.'], 'label_ids': tensor([[  290,    19,     3,     9,   385,  3202,  1180,    30,     8,  2608,\n",
      "             5,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ 2759, 26675,    33,  3823,   544,   416,    12,     3,     9,  3724,\n",
      "            30,  1001,  6428,    26,  7091,     5,     1,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ 5245, 27424,     7,    33,  5989,    42,  8191,    16,  2450,    50,\n",
      "          1496,     5,     1,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100],\n",
      "        [ 2759,  3887, 13060,   284,   119,     5,     1,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100]]), 'similar_ids': tensor([[  290,    19,     3,     9,   385,  3202,     5,     1,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2759, 26675,  3823,   416,    12,     3,     9,  3724,     5,     1,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 3892,     7,  5989,     1,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2759,  3887,    33,  2327,   284,   119,     5,     1,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'similar_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'contrastive_ids': tensor([[  290,    19,     3,     9,   385,  4940,     5,     1,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [  276,   413,  8497,  9182,    16,     3,     9,  8235,     5,     1,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 9428,    19,  5989,     1,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2759, 10003,    33,  2327,   284,   119,     5,     1,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'contrastive_attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for d in dataloader:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xz479/miniconda3/envs/latent-diff/lib/python3.8/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('google/flan-t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "org = model.get_encoder()(input_ids=d['encoder_input_ids'], attention_mask=d['attention_mask'])\n",
    "sim = model.get_encoder()(input_ids=d['similar_ids'], attention_mask=d['similar_attention_mask'])\n",
    "con = model.get_encoder()(input_ids=d['contrastive_ids'], attention_mask=d['contrastive_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "def get_simcse_loss(org, sim, con, pooler='avg', temp=0.05, hard_negative_weight=1):\n",
    "    if sim is None and con is None:\n",
    "        return 0\n",
    "    \n",
    "    cos_sim = nn.CosineSimilarity(dim=-1)\n",
    "    batch_size = org.shape[0]\n",
    "    \n",
    "    # Pooling and normalization\n",
    "    if pooler == 'avg':\n",
    "        org_pooled = F.normalize(org.mean(dim=1), p=2, dim=-1)\n",
    "        if sim is not None:\n",
    "            sim_pooled = F.normalize(sim.mean(dim=1), p=2, dim=-1)\n",
    "        if con is not None:\n",
    "            con_pooled = F.normalize(con.mean(dim=1), p=2, dim=-1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    if sim_pooled is not None:\n",
    "        # For supervised SimCSE, compare org with sim\n",
    "        pos_cos = cos_sim(org_pooled.unsqueeze(1), sim_pooled.unsqueeze(0)) / temp\n",
    "        \n",
    "        if con_pooled is not None:\n",
    "            # Add hard negatives if provided\n",
    "            con_cos = cos_sim(org_pooled.unsqueeze(1), con_pooled.unsqueeze(0)) / temp\n",
    "            base = torch.cat([pos_cos, con_cos], 1)\n",
    "        else:\n",
    "            base = pos_cos\n",
    "            \n",
    "        labels = torch.arange(batch_size).long().to(org.device)\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        \n",
    "        if con_pooled is not None:\n",
    "            # Apply weights for hard negatives\n",
    "            weights = torch.tensor(\n",
    "                [[0.0] * (base.size(-1) - con_cos.size(-1)) + [0.0] * i + [hard_negative_weight] + [0.0] * (con_cos.size(-1) - i - 1) \n",
    "                 for i in range(con_cos.size(-1))]).to(org.device)\n",
    "            base += weights\n",
    "        \n",
    "        loss = loss_fct(base, labels)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org pooled norm: tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<LinalgVectorNormBackward0>)\n",
      "Sim pooled norm: tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<LinalgVectorNormBackward0>)\n",
      "Con pooled norm: tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<LinalgVectorNormBackward0>)\n",
      "Positive cosine similarities:\n",
      "tensor([[1.0000, 0.5376, 0.5670, 0.7013],\n",
      "        [0.5376, 1.0000, 0.6180, 0.7106],\n",
      "        [0.5670, 0.6180, 1.0000, 0.5380],\n",
      "        [0.7013, 0.7106, 0.5380, 1.0000]], grad_fn=<MulBackward0>)\n",
      "Negative cosine similarities:\n",
      "tensor([[0.6207, 0.5539, 0.6196, 0.6437],\n",
      "        [0.4293, 0.6174, 0.5574, 0.4936],\n",
      "        [0.5422, 0.5650, 0.6543, 0.5008],\n",
      "        [0.5024, 0.6307, 0.5809, 0.6021]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0055, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_simcse_loss(org.last_hidden_state, org.last_hidden_state, con.last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['encoder_input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 768])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org.last_hidden_state.mean(dim=1).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 768])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.last_hidden_state.mean(dim=1).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6207, 0.5539, 0.6196, 0.6437],\n",
       "        [0.4293, 0.6174, 0.5574, 0.4936],\n",
       "        [0.5422, 0.5650, 0.6543, 0.5008],\n",
       "        [0.5024, 0.6307, 0.5809, 0.6021]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine=nn.CosineSimilarity(dim=-1)\n",
    "cosine(org.last_hidden_state.mean(dim=1).unsqueeze(1), con.last_hidden_state.mean(dim=1).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shapes:\n",
      "org shape: torch.Size([3, 4, 8])\n",
      "sim shape: torch.Size([3, 4, 8])\n",
      "con shape: torch.Size([3, 4, 8])\n",
      "\n",
      "Debug - Normalized vector norms:\n",
      "org_pooled norms: tensor([1.0000, 1.0000, 1.0000])\n",
      "sim_pooled norms: tensor([1.0000, 1.0000, 1.0000])\n",
      "con_pooled norms: tensor([1.0000, 1.0000, 1.0000])\n",
      "\n",
      "Debug - Similarity matrices (before temperature scaling):\n",
      "Positive similarities (org vs sim):\n",
      "tensor([[0.0491, 0.0142, 0.0320],\n",
      "        [0.0117, 0.0498, 0.0141],\n",
      "        [0.0283, 0.0100, 0.0499]])\n",
      "\n",
      "Negative similarities (org vs con):\n",
      "tensor([[ 0.0386,  0.0020, -0.0196],\n",
      "        [ 0.0071,  0.0023, -0.0100],\n",
      "        [ 0.0326,  0.0115, -0.0061]])\n",
      "\n",
      "Debug - Final logits matrix:\n",
      "tensor([[ 0.0491,  0.0142,  0.0320,  0.0886,  0.0020, -0.0196],\n",
      "        [ 0.0117,  0.0498,  0.0141,  0.0071,  0.0523, -0.0100],\n",
      "        [ 0.0283,  0.0100,  0.0499,  0.0326,  0.0115,  0.0439]])\n",
      "\n",
      "Loss: 1.4543529748916626\n",
      "\n",
      "Verification of a single example:\n",
      "Similarity between org and sim: 0.9819483757019043\n",
      "Similarity between org and con: 0.771674633026123\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Create sample embeddings\n",
    "batch_size = 3\n",
    "seq_length = 4\n",
    "hidden_dim = 8\n",
    "\n",
    "# Create original embeddings\n",
    "org = torch.randn(batch_size, seq_length, hidden_dim)\n",
    "# Create similar embeddings (slightly perturbed version of org)\n",
    "sim = org + 0.1 * torch.randn_like(org)\n",
    "# Create contrasting embeddings (completely different)\n",
    "con = torch.randn(batch_size, seq_length, hidden_dim)\n",
    "\n",
    "def get_simcse_loss(org, sim, con, pooler='avg', temp=0.05, hard_negative_weight=1):\n",
    "    if sim is None and con is None:\n",
    "        return 0\n",
    "    \n",
    "    cos_sim = nn.CosineSimilarity(dim=-1)\n",
    "    batch_size = org.shape[0]\n",
    "    \n",
    "    # Pooling and normalization\n",
    "    if pooler == 'avg':\n",
    "        org_pooled = F.normalize(org.mean(dim=1), p=2, dim=-1)\n",
    "        if sim is not None:\n",
    "            sim_pooled = F.normalize(sim.mean(dim=1), p=2, dim=-1)\n",
    "        if con is not None:\n",
    "            con_pooled = F.normalize(con.mean(dim=1), p=2, dim=-1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    print(\"\\nDebug - Normalized vector norms:\")\n",
    "    print(\"org_pooled norms:\", torch.norm(org_pooled, dim=1))  # Should all be 1\n",
    "    print(\"sim_pooled norms:\", torch.norm(sim_pooled, dim=1))  # Should all be 1\n",
    "    print(\"con_pooled norms:\", torch.norm(con_pooled, dim=1))  # Should all be 1\n",
    "    \n",
    "    if sim_pooled is not None:\n",
    "        # Calculate similarity matrices\n",
    "        pos_cos = cos_sim(org_pooled.unsqueeze(1), sim_pooled.unsqueeze(0)) \n",
    "        con_cos = cos_sim(org_pooled.unsqueeze(1), con_pooled.unsqueeze(0))\n",
    "        \n",
    "        print(\"\\nDebug - Similarity matrices (before temperature scaling):\")\n",
    "        print(\"Positive similarities (org vs sim):\")\n",
    "        print(pos_cos * temp)  # Multiply by temp to see raw similarities\n",
    "        print(\"\\nNegative similarities (org vs con):\")\n",
    "        print(con_cos * temp)  # Multiply by temp to see raw similarities\n",
    "        \n",
    "        # Combine positive and negative similarities\n",
    "        base = torch.cat([pos_cos, con_cos], 1)\n",
    "        \n",
    "        # Create labels (diagonal should have highest values)\n",
    "        labels = torch.arange(batch_size).long()\n",
    "        \n",
    "        # Apply weights for hard negatives\n",
    "        weights = torch.tensor(\n",
    "            [[0.0] * (base.size(-1) - con_cos.size(-1)) + [0.0] * i + [hard_negative_weight] + [0.0] * (con_cos.size(-1) - i - 1) \n",
    "             for i in range(con_cos.size(-1))])\n",
    "        \n",
    "        base += weights\n",
    "        \n",
    "        print(\"\\nDebug - Final logits matrix:\")\n",
    "        print(base * temp)  # Multiply by temp to see raw logits\n",
    "        \n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(base, labels)\n",
    "        \n",
    "        print(\"\\nLoss:\", loss.item())\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    return 0\n",
    "\n",
    "# Test the function\n",
    "print(\"Input shapes:\")\n",
    "print(\"org shape:\", org.shape)\n",
    "print(\"sim shape:\", sim.shape)\n",
    "print(\"con shape:\", con.shape)\n",
    "\n",
    "loss = get_simcse_loss(org, sim, con)\n",
    "\n",
    "# Let's also verify the actual similarity between org and sim embeddings\n",
    "# for a single example\n",
    "print(\"\\nVerification of a single example:\")\n",
    "example_idx = 0\n",
    "org_example = F.normalize(org[example_idx].mean(dim=0), p=2, dim=-1)\n",
    "sim_example = F.normalize(sim[example_idx].mean(dim=0), p=2, dim=-1)\n",
    "con_example = F.normalize(con[example_idx].mean(dim=0), p=2, dim=-1)\n",
    "\n",
    "print(\"Similarity between org and sim:\", F.cosine_similarity(org_example, sim_example, dim=0).item())\n",
    "print(\"Similarity between org and con:\", F.cosine_similarity(org_example, con_example, dim=0).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latent-diff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
